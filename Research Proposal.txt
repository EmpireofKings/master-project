# Problem Setting

Our goal is to train a team of autonomous drones to explore an unknown area as most efficient
as possible in order to find a given target. This setting leads to a wide range of problems.
We want to focus on the following aspects, whereby the order represents our priority.

1.	Synchronisation
Every drone in the team must synchronize with other drones to avoid work that has already been done.
This implies that the drone’s individual decision-making, i.e. path planning depends not only on its
own past decisions and its current environment, but also on decisions of other drones. The decision-making
may be done by a central control drone or by all drones simultaneously. This setting further implies that
the connection to other drones may get lost if the drones swarm out too far from each other.

2.	SLAM
Every drone must explore its surrounding area in order to find the target. This is known as Simultaneous 
Localisation and Mapping (SLAM). This can be done using any available sensor input, e.g. camera frames and GPS.

3.	Object Recognition
The team of drones should be able to identify any given target and communicate this event back to the operator.

Assumptions
-	Search area is limited beforehand by the operator
-	Target is easy to identify
-	Exploration is time-critical
-	Drones are able to fly stable in the given direction and are already able to avoid small obstacles (trees, power poles, etc.) by themselves.

Out of scope:
-	Technical details about hardware and communication
-	Detection of many targets in the given area
-	Optimization with regard to most efficient use of hardware resources

#State of the art
Existing
--Reinforcement learning for a single bot, search and rescue
--Methods to acheive shortest path(RL)
--Mostly tested in simulation,not implemented in real-time

We have to incorporate both the ideas

--Delay between action and rewards
--DL assume independent, while in RL states are highly correlated
--Effectivenss is dependent on the exploration strategy used
--Frontier exploration
--How well does it resemble the real-world scenario

To do
--learn collision avoidance
--exploration
--victim discovery and targeted exploration

Papers
--Border et al (2015) Learning to Save Lives - Using Reinforcement Learning with Environment Features for Efficient Robot Search a.pdf
--Challita et al (2018) Deep Reinforcement Learning for Interference-Aware Path Planning of Cellular-Connected UAVs.pdf


#Data Foundation
Our ultimate aim is to use a team of autonomous drones for Search and Rescue missions via simulations. Hence the requirement for real time data is not mandatory.
The simulator uses plugin that can you can drop into any existing, or new, unreal environment. It can generate training data through images for each frame.
A more complex way to generate training data is through Application programming interfaces (API). These APIs collect sensor and ground truth data from the drones, as well as various images. With their help, the code used to test drones in the simulator can be transferred to an offboard computer and used on real drones
The following are a couple of simulation platforms which will be evaluated in due course for its complexity, performance, financial cost and hardware requirements:
•	SITL (Software In The Loop) most commonly used by developers. 
•	Gazebo is the official DARPA virtual robotics simulator
•	XPlane-10 a commercial flight simulator with a rich 3D interface
•	RealFlight a commercial flight simulator with a rich 3D interface and ability to design custom vehicles
•	AirSim :platform for artificial intelligence (AI) research to experiment with deep learning, computer vision and reinforcement learning algorithms for autonomous vehicles.

# Tangible outcomes
We will be making use of the open source software for our project and provide results via software documentation (story about requirements, design, implementation). In addition to this, we will also be including a demo or a tutorial in the form a video representation. The video will depict the simulation of the drone navigating through a known/unknown path in search of a particular object/person, while avoiding obstacles on the way. The data regarding the location and optimal path will be transmitted to the central hub after which the rescue mission can take place.

# Team
Our team consists of
- Benjamin Hogstad

- Ramya Raghuraman

- Krithika Murugesan 

- Mohana Nyamanahalli Venkatesha

- Michael Ruchte
Experience in Computer Vision, working experience in software development
